<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>Intro to transformer models on Social / Business Data Science 2023</title><link>https://aaubs.github.io/ds23/en/m4/03_intro-to-transformer-models/</link><description>Recent content in Intro to transformer models on Social / Business Data Science 2023</description><generator>Hugo -- gohugo.io</generator><language>en-US</language><atom:link href="https://aaubs.github.io/ds23/en/m4/03_intro-to-transformer-models/index.xml" rel="self" type="application/rss+xml"/><item><title>Introduction to transformers</title><link>https://aaubs.github.io/ds23/en/m4/03_intro-to-transformer-models/1_basictm/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aaubs.github.io/ds23/en/m4/03_intro-to-transformer-models/1_basictm/</guid><description>Literature Sutskever, I., Vinyals, O., &amp;amp;amp; Le, Q. V. (2014). Sequence to sequence learning with neural networks. Advances in neural information processing systems, 27.
Vaswani, A., Shazeer, N., Parmar, N., Uszkoreit, J., Jones, L., Gomez, A. N., &amp;amp;hellip; &amp;amp;amp; Polosukhin, I. (2017). Attention is all you need. Advances in neural information processing systems, 30.
The illustrated transformer
Simple transformer LM
Notebooks Seq2Seq - Neural Machine Translation
Simple transformer LM</description></item><item><title>Sentence-Transformers SBERT</title><link>https://aaubs.github.io/ds23/en/m4/03_intro-to-transformer-models/2_sbert/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aaubs.github.io/ds23/en/m4/03_intro-to-transformer-models/2_sbert/</guid><description>Sentence Transformers are a recent breakthrough in natural language processing that can generate dense, high-quality embeddings of sentences, enabling accurate semantic similarity comparisons between sentences. What makes them particularly exciting for businesses and social science applications is their ability to enable more intuitive, meaningful language-based search, content deduplication, and clustering. With Sentence Transformers, businesses can enhance the accuracy of their search engines, provide more accurate recommendations, and reduce redundancy in content databases.</description></item><item><title>Exercise Session 3</title><link>https://aaubs.github.io/ds23/en/m4/03_intro-to-transformer-models/3_exercise-session-3_pytorch/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aaubs.github.io/ds23/en/m4/03_intro-to-transformer-models/3_exercise-session-3_pytorch/</guid><description>In this session, you will learn how to finetune SBERT embeddings and use them in downstream tasks. They will also practice using SBERT in a variety of business scenarios.
Hate Speech Dataset Online hate speech on social media networks can influence hate violence and even crimes against a certain group of people in this digital age. According to FBI statistics, hate-related attacks on specific groups of people are at a 16-year high [1].</description></item><item><title>Group assignment 3</title><link>https://aaubs.github.io/ds23/en/m4/03_intro-to-transformer-models/4_group_assignment-3/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aaubs.github.io/ds23/en/m4/03_intro-to-transformer-models/4_group_assignment-3/</guid><description>Portfolio Exercise 3: Introduction Task Create something cool ðŸš€ using SBERT and semantic search or perhaps more?! That&amp;rsquo;s a bit of a vague description but there are many options.
You are welcome to use images and CLIP You can also use SetFit for supervised tasks with SBERT models. Here are some projects for inspiration:
GIF search engine Youtube search some more ideas:
get some podcast transcripts for a specific topic (or create transcripts with Whisper - search for OpenAI Whisper Colab) Finetune an SBERT model using domain adaptation Embed and build a search engine Build a Gradio app Feel free to choose any of these ideas or come up with your own.</description></item></channel></rss>